{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Em24asT7zrhE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvHHe4W_idWV"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # Step 1: Extract username\n",
    "    username_match = re.search(r\"([^\\n]+)\\s+(?:2nd degree|3rd degree)\", data)\n",
    "    username = username_match.group(1).strip() if username_match else \"Not available\"\n",
    "\n",
    "    # Step 2: Extract number of connections\n",
    "    connections_match = re.search(r\"(\\d+\\+?)\\s+connections\", data)\n",
    "    connections = connections_match.group(1) if connections_match else \"Not available\"\n",
    "\n",
    "    # Step 3: Extract experience and calculate total years and months\n",
    "    experience_pattern = r\"Experience(.*?)Education\"\n",
    "    experience_section = re.search(experience_pattern, data, re.DOTALL)\n",
    "    experience_section = experience_section.group(1).strip() if experience_section else \"\"\n",
    "\n",
    "    duration_pattern = r\"(\\d+)\\s+yrs(?:\\s+(\\d+)\\s+mos)?\"\n",
    "    matches = re.findall(duration_pattern, experience_section)\n",
    "\n",
    "    # Remove duplicates by converting to a set\n",
    "    unique_matches = list(set(matches))\n",
    "\n",
    "    # Calculate total years and months\n",
    "    total_years = 0\n",
    "    total_months = 0\n",
    "    for match in unique_matches:\n",
    "        years = int(match[0]) if match[0] else 0\n",
    "        months = int(match[1]) if match[1] else 0\n",
    "        total_years += years\n",
    "        total_months += months\n",
    "\n",
    "    # Convert months to years if needed\n",
    "    total_years += total_months // 12\n",
    "    total_months = total_months % 12\n",
    "\n",
    "    # Step 4: Extract education\n",
    "    education_pattern = r\"Education(.*?)(?:Licenses & certifications|Projects|$)\"\n",
    "    education = re.search(education_pattern, data, re.DOTALL)\n",
    "    education = education.group(1).strip() if education else \"Not available\"\n",
    "\n",
    "    # Step 5: Extract the highest-priority degree using broader matching\n",
    "    degree_patterns = {\n",
    "        \"PhD\": r\"ph\\.?d|doctorate|doctoral\",\n",
    "        \"MS\": r\"m\\.?s|master|masters|m\\.sc\",\n",
    "        \"BS\": r\"b\\.?s|bachelor|b\\.sc\"\n",
    "    }\n",
    "\n",
    "\n",
    "    def extract_highest_priority_degree(data, degree_patterns):\n",
    "        for degree, pattern in degree_patterns.items():\n",
    "            if re.search(pattern, data, re.IGNORECASE):\n",
    "                return degree\n",
    "        return \"None\"\n",
    "\n",
    "    highest_degree = extract_highest_priority_degree(education, degree_patterns)\n",
    "\n",
    "    # Step 6: Extract recent post timing\n",
    "    post_pattern = r'(\\d+)(mo|d|yr)'\n",
    "    post_match = re.findall(post_pattern, data)\n",
    "    if post_match:\n",
    "        number, unit = post_match[0]\n",
    "        if unit == 'mo':\n",
    "            recent_post = f\"{number} months\"\n",
    "        elif unit == 'yr':\n",
    "            recent_post = f\"{number} years\"\n",
    "        elif unit == 'd':\n",
    "            recent_post = f\"{number} days\"\n",
    "        else:\n",
    "            recent_post = \"Not available\"\n",
    "    else:\n",
    "        recent_post = \"Not available\"\n",
    "\n",
    "    # Step 7: Extract reactions, comments, and repost counts\n",
    "    reaction_regex = r'like\\w*\\s*(\\d+)\\s*'\n",
    "    comments_regex = r'(\\d+)\\s*comments'\n",
    "    reposts_regex = r'(\\d+)\\s*reposts'\n",
    "    reaction_match = re.search(reaction_regex, data)\n",
    "    comments_match = re.search(comments_regex, data)\n",
    "    reposts_match = re.search(reposts_regex, data)\n",
    "    reactions = reaction_match.group(1) if reaction_match else \"Not available\"\n",
    "    comments = comments_match.group(1) if comments_match else \"Not available\"\n",
    "    reposts = reposts_match.group(1) if reposts_match else \"Not available\"\n",
    "\n",
    "    # Compile all results into a dictionary\n",
    "    results = {\n",
    "        \"Username\": username,\n",
    "        \"Education\": highest_degree,\n",
    "        \"Experience (Years)\": total_years,\n",
    "        \"Experience (Months)\": total_months,\n",
    "        \"Connections\": connections,\n",
    "        \"Recent Post\": recent_post,\n",
    "        \"Reactions on Recent Post\": reactions,\n",
    "        \"Comments on Recent Post\": comments,\n",
    "        \"Repost Count on Recent Post\": reposts,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lkL6nHO0iiYW",
    "outputId": "723d06e8-79c8-4c57-e7a4-2f17ebdacec3"
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 24083: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProfile-verification-for-Car-Rental\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msyed_azhar.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m output2 \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m output2\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m, in \u001b[0;36mprocess_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_file\u001b[39m(file_path):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 5\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Step 1: Extract username\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     username_match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m([^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn]+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+(?:2nd degree|3rd degree)\u001b[39m\u001b[38;5;124m\"\u001b[39m, data)\n",
      "File \u001b[1;32mc:\\Users\\DANISH LAPTOP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,decoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 24083: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "file_path2 = 'D:\\Profile-verification-for-Car-Rental\\syed_azhar.txt'\n",
    "output2 = process_file(file_path2)\n",
    "\n",
    "\n",
    "for key, value in output2.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
